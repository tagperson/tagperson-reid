# encoding: utf-8
"""
anonymous
anonymous
"""

import copy
import itertools
from collections import defaultdict
from typing import Optional, List

import numpy as np
from torch.utils.data.sampler import Sampler

from fastreid.utils import comm

import random
import time

def no_index(a, b):
    assert isinstance(a, list)
    return [i for i, j in enumerate(a) if j != b]


def reorder_index(batch_indices, world_size, data_source):
    r"""Reorder indices of samples to align with DataParallel training.
    In this order, each process will contain all images for one ID, triplet loss
    can be computed within each process, and BatchNorm will get a stable result.
    Args:
        batch_indices: A batched indices generated by sampler
        world_size: number of process
    Returns:

    """
    mini_batchsize = len(batch_indices) // world_size
    reorder_indices = []
    for i in range(0, mini_batchsize):
        for j in range(0, world_size):
            reorder_indices.append(batch_indices[i + j * mini_batchsize])
    return reorder_indices


class ExpandNaiveIdentitySampler(Sampler):
    """
    Randomly sample N identities, then for each identity,
    randomly sample K instances, therefore batch size is N*K.
    Args:
    - data_source (list): list of (img_path, pid, camid).
    - num_instances (int): number of instances per identity in a batch.
    - batch_size (int): number of examples in a batch.
    """

    def __init__(self, data_source: str, mini_batch_size: int, num_instances: int, seed: Optional[int] = None, expand_camera_enabled=False):
        self.data_source = data_source
        self.num_instances = num_instances
        self.num_pids_per_batch = mini_batch_size // self.num_instances
        self._rank = comm.get_rank()
        self._world_size = comm.get_world_size()
        self.batch_size = mini_batch_size * self._world_size

        self.pid_index = defaultdict(list)

        for index, info in enumerate(data_source):
            pid = info[1]
            self.pid_index[pid].append(index)

        self.pids = sorted(list(self.pid_index.keys()))
        self.num_identities = len(self.pids)

        # organize camera dict
        self.expand_camera_enabled = expand_camera_enabled
        self.expand_camera_dict = defaultdict(list)
        self.expand_pid_camera_dict = {}
        for index, info in enumerate(data_source):
            option_dict = info[4]
            pid = info[1]
            camera_idx = option_dict['camera_idx']
            image_info = {
                'index': index,
                'pid': pid,
                'camera_idx': camera_idx
            }
            self.expand_camera_dict[camera_idx].append(image_info)

            # append to self.expand_pid_camera_dict
            if pid not in self.expand_pid_camera_dict:
                self.expand_pid_camera_dict[pid] = {}
            if camera_idx not in self.expand_pid_camera_dict[pid]:
                self.expand_pid_camera_dict[pid][camera_idx] = []
            self.expand_pid_camera_dict[pid][camera_idx].append(image_info)
        self.expand_camera_idx_list = list(self.expand_camera_dict.keys())

        # resolution
        self.index_pid = dict()
        self.pid_resolutions = defaultdict(list)
        self.num_resolution_per_batch = 4
        self.resolution_index_dic = dict()
        self.num_pids_per_resolution = self.num_pids_per_batch // self.num_resolution_per_batch
        if self.num_pids_per_resolution <= 0:
            raise ValueError(f"num_pids_per_resolution <= 0")        
        for index, info in enumerate(data_source):
            pid = info[1]
            camid = info[2]
            option_dict = info[4]
            img_width = option_dict['img_width']
            resolution_id = get_resolution_id(img_width)
            self.index_pid[index] = pid
            self.pid_resolutions[pid].append(resolution_id)
            if resolution_id not in self.resolution_index_dic.keys():
                self.resolution_index_dic[resolution_id]=defaultdict(list)
            self.resolution_index_dic[resolution_id][pid].append(index)

        # expand end


        if seed is None:
            seed = comm.shared_random_seed()
        self._seed = int(seed)

    def __iter__(self):
        start = self._rank
        yield from itertools.islice(self._infinite_indices(), start, None, self._world_size)

    def _infinite_indices(self):
        np.random.seed(self._seed)
        while True:
            avl_pids = copy.deepcopy(self.pids)
            batch_idxs_dict = {}

            batch_indices = []
            time0 = time.time()
            while len(avl_pids) >= self.num_pids_per_batch:
                selected_pids = np.random.choice(avl_pids, self.num_pids_per_batch, replace=False).tolist()
                for pid in selected_pids:
                    # Register pid in batch_idxs_dict if not
                    if pid not in batch_idxs_dict:
                        idxs = copy.deepcopy(self.pid_index[pid])
                        if len(idxs) < self.num_instances:
                            idxs = np.random.choice(idxs, size=self.num_instances, replace=True).tolist()
                        np.random.shuffle(idxs)
                        batch_idxs_dict[pid] = idxs

                    avl_idxs = batch_idxs_dict[pid]
                    for _ in range(self.num_instances):
                        batch_indices.append(avl_idxs.pop(0))

                    if len(avl_idxs) < self.num_instances: avl_pids.remove(pid)

                if len(batch_indices) == self.batch_size:
                    # time1 = time.time() - time0
                    # print(f"prepare normal batch cost: {time1} seconds..")
                    # time0 = time.time()
                    if self.expand_camera_enabled:
                        expand_training_batch_camera = self.fetch_expand_training_batch_resolution()
                        assert len(expand_training_batch_camera) == len(batch_indices)

                    # time1 = time.time() - time0
                    # print(f"prepare expand_camera batch cost: {time1} seconds..")
                    # time0 = time.time()

                    # oranize
                    combined_batch_indices = []
                    mini_batch_size = self.batch_size // self._world_size
                    for wid in range(self._world_size):
                        combined_batch_indices.extend(batch_indices[wid * mini_batch_size : (wid+1) * mini_batch_size])
                        if self.expand_camera_enabled:
                            combined_batch_indices.extend(expand_training_batch_camera[wid * mini_batch_size : (wid+1) * mini_batch_size])


                    # yield from reorder_index(batch_indices, self._world_size)
                    yield from reorder_index(combined_batch_indices, self._world_size, self.data_source)
                    combined_batch_indices = []
                    batch_indices = []


    def fetch_expand_training_batch_camera(self):
        # camera num should larger than `P` in each patch
        assert len(self.expand_camera_idx_list) > self.num_pids_per_batch, f"expect num_cameras >= num_pids_per_batch, got {len(self.expand_camera_idx_list)} and {self.num_pids_per_batch} instead."

        # should prepare `mini_batch_size * self._world_size`
        expand_batch_indices = []
        for i in range(self._world_size):
            camera_idx_list = np.random.choice(self.expand_camera_idx_list, size=self.num_pids_per_batch, replace=False)
            random.shuffle(camera_idx_list)
            for cid in camera_idx_list:
                # random one person
                one_image_info = np.random.choice(self.expand_camera_dict[cid], size=1, replace=False)
                current_pid = one_image_info[0]['pid']
                # select `K/2-1` images with same pid but different cameras
                other_camera_idx_list = set(self.expand_camera_idx_list).difference(set([cid]))
                K = self.num_instances
                assert K % 2 == 0, f"num_instance should be even, got {num_instance}"
                current_pid_other_camera_list = []
                # TODO: use exact different camera ids
                for other_cid in other_camera_idx_list:
                    if other_cid in self.expand_pid_camera_dict[current_pid]:
                        current_pid_other_camera_list.extend(self.expand_pid_camera_dict[current_pid][other_cid])
                assert len(current_pid_other_camera_list) >= int(K/2-1), f"len(current_pid_other_camera_list) should larger than K/2-1, got {len(current_pid_other_camera_list)} and {K/2-1}"
                current_pid_other_images = np.random.choice(current_pid_other_camera_list, int(K/2-1), replace=False)
                
                # select `K/2` images with same camera but different pids
                other_pid_same_camera_images = []
                while len(other_pid_same_camera_images) < int(K/2):
                    selected_image_info = np.random.choice(self.expand_camera_dict[cid], size=1, replace=False)
                    if selected_image_info[0]['pid'] == current_pid:
                        continue
                    other_pid_same_camera_images.append(selected_image_info[0])
                
                # now the result has been produce as [one_image_info, current_pid_other_image, other_pid_same_camera_images]
                expand_batch_images = []
                expand_batch_images.extend(one_image_info)
                expand_batch_images.extend(current_pid_other_images)
                expand_batch_images.extend(other_pid_same_camera_images)
                # print(other_pid_same_camera_images)
                # exit()
                expand_batch_indices.extend([e['index'] for e in expand_batch_images])

        
        return expand_batch_indices


    def fetch_expand_training_batch_resolution(self):
        # should prepare `mini_batch_size * self._world_size`
        expand_batch_indices = []
        for i in range(self._world_size):
            batch_indices = []
            resolutions = np.random.choice(list(self.resolution_index_dic.keys()), size=self.num_resolution_per_batch, replace=True)
            for r in resolutions:
                pids = np.random.choice(list(self.resolution_index_dic[r].keys()), size=self.num_pids_per_resolution, replace=True)
                for p in pids:
                    idxs = np.random.choice(self.resolution_index_dic[r][p], size=self.num_instances,replace=True)
                    random.shuffle(idxs)
                    batch_indices.extend(idxs)
            expand_batch_indices.extend(batch_indices)

        return expand_batch_indices

def get_resolution_id(width: int):
    resolution_id = width // 25
    return resolution_id
